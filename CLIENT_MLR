import duckdb
import os
import pandas as pd
import streamlit as st
import polars as pl

# Configure the Streamlit page
st.set_page_config(
    page_title="MLR Analysis - DLT Dashboard",
    page_icon="ðŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("MLR Analysis Dashboard")

@st.cache_data(ttl=3600)
def load_data_from_motherduck():
    """Load data from MotherDuck with caching"""
    try:
        # Step 1: Set your MotherDuck token
        os.environ["MOTHERDUCK_TOKEN"] = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6Imxlb2Nhc2V5MEBnbWFpbC5jb20iLCJzZXNzaW9uIjoibGVvY2FzZXkwLmdtYWlsLmNvbSIsInBhdCI6IndUUEFydnRna19INlVTbDFGamlyVGFoa3ZoVUtrX2pOZ05XcmtNd0VTQXciLCJ1c2VySWQiOiJmNDAzMTg5ZS05ODIxLTQ2NzktYjRmZS0wZWMyMjY0NDQyZjgiLCJpc3MiOiJtZF9wYXQiLCJyZWFkT25seSI6ZmFsc2UsInRva2VuVHlwZSI6InJlYWRfd3JpdGUiLCJpYXQiOjE3NTIyMjMzODJ9.BjvBqQ8dpgYkbW98IpxE8QTwGJbWexsctB4qNxaxGpo" 

        # Step 2: Connect to your MotherDuck database
        con = duckdb.connect("md:my_CIL_DB")

        # Step 3: Query the tables and load into pandas DataFrames
        with st.spinner("Loading data from MotherDuck..."):
            GROUP_CONTRACT = con.execute("SELECT * FROM my_dataset.group_contract").fetchdf()
            CLAIMS = con.execute("SELECT * FROM my_dataset.claims").fetchdf()
            GROUPS = con.execute("SELECT * FROM my_dataset.all_group").fetchdf()
            DEBIT = con.execute("SELECT * FROM my_dataset.debit_note").fetchdf()
            PA = con.execute("SELECT * FROM my_dataset.total_pa_procedures").fetchdf()
            
            # Convert to Polars DataFrames
            GROUP_CONTRACT = pl.from_pandas(GROUP_CONTRACT)
            CLAIMS = pl.from_pandas(CLAIMS)
            GROUPS = pl.from_pandas(GROUPS)
            DEBIT = pl.from_pandas(DEBIT)
            PA = pl.from_pandas(PA)
            
        con.close()
        return PA, GROUP_CONTRACT, CLAIMS, GROUPS, DEBIT
        
    except Exception as e:
        st.error(f"Error loading data: {str(e)}")
        return None, None, None, None, None

def calculate_mlr(PA, GROUP_CONTRACT, CLAIMS, GROUPS, DEBIT):
    """Calculate MLR metrics"""
    try:
        # --- PA MLR ---
        PA = PA.with_columns([
            pl.col('requestdate').cast(pl.Datetime),
            pl.col('granted').cast(pl.Float64, strict=False)
        ])
        group_contract_dates = GROUP_CONTRACT.select(['groupname', 'startdate', 'enddate']).with_columns([
            pl.col('startdate').cast(pl.Datetime),
            pl.col('enddate').cast(pl.Datetime)
        ])
        pa_filtered = PA.join(group_contract_dates, on='groupname', how='inner').filter(
            (pl.col('requestdate') >= pl.col('startdate')) & (pl.col('requestdate') <= pl.col('enddate'))
        )
        PA_mlr = pa_filtered.group_by('groupname').agg(
            pl.col('granted').sum().alias('Total cost')
        )

        # --- CLAIMS MLR ---
        CLAIMS = CLAIMS.with_columns([
            pl.col('approvedamount').cast(pl.Float64),
            pl.col('encounterdatefrom').cast(pl.Datetime),
            pl.col('nhisgroupid').cast(pl.Utf8)
        ])
        GROUPS = GROUPS.with_columns(pl.col('groupid').cast(pl.Utf8))
        claims_with_group = CLAIMS.join(
            GROUPS.select(['groupid', 'groupname']),
            left_on='nhisgroupid', right_on='groupid', how='inner'
        )
        claims_with_dates = claims_with_group.join(
            group_contract_dates, on='groupname', how='inner'
        ).filter(
            (pl.col('encounterdatefrom') >= pl.col('startdate')) & (pl.col('encounterdatefrom') <= pl.col('enddate'))
        )
        claims_mlr = claims_with_dates.group_by('groupname').agg(
            pl.col('approvedamount').sum().alias('Total cost')
        ).sort('Total cost', descending=True)

        # --- DEBIT NOTE (last 12 months) ---
        today = pd.Timestamp.today().normalize()
        first_of_month_12_months_ago = (today.replace(day=1) - pd.DateOffset(months=12)).replace(day=1)
        # Ensure DEBIT is pandas DataFrame for filtering
        if not isinstance(DEBIT, pd.DataFrame):
            DEBIT = DEBIT.to_pandas()
        DEBIT['from'] = pd.to_datetime(DEBIT['from'])
        CURRENT_DEBIT = DEBIT[(DEBIT['from'] >= first_of_month_12_months_ago) & (DEBIT['from'] <= today)]
        DEBIT_BY_CLIENT = CURRENT_DEBIT.groupby('company_name', as_index=False)['amount'].sum()
        DEBIT_BY_CLIENT = DEBIT_BY_CLIENT.rename(columns={'company_name': 'groupname'})
        DEBIT_BY_CLIENT = DEBIT_BY_CLIENT.sort_values('amount', ascending=False)

        # --- Merge Results ---
        debit_df = pl.from_pandas(DEBIT_BY_CLIENT.rename(columns={'amount': 'Total cost(DEBIT_BY_CLIENT)'}))
        pa_df = PA_mlr.rename({'Total cost': 'Total cost(PA)'}).with_columns(
            (pl.col('Total cost(PA)') * 0.4).round(2).alias('PA40%')
        )
        claims_df = claims_mlr.rename({'Total cost': 'Total cost(claims)'})

        # Calculate PA MLR DataFrame
        pa_merged = debit_df.join(
            pa_df.select(['groupname', 'Total cost(PA)', 'PA40%']),
            on='groupname', how='outer'
        )
        pa_merged = pa_merged.with_columns(
            (pl.col('Total cost(DEBIT_BY_CLIENT)') * 0.10).round(2).alias('commission')
        ).select([
            'groupname',
            'Total cost(DEBIT_BY_CLIENT)',
            'Total cost(PA)',
            'PA40%',
            'commission'
        ])
        pa_merged = pa_merged.with_columns([
            (
                (pl.col('PA40%').fill_null(0) +
                    pl.col('commission').fill_null(0)
                ) / pl.col('Total cost(DEBIT_BY_CLIENT)').fill_null(0) * 100
            ).round(2).alias('MLR(PA) (%)')
        ])

        # Calculate CLAIMS MLR DataFrame
        claims_merged = debit_df.join(
            claims_df.select(['groupname', 'Total cost(claims)']),
            on='groupname', how='outer'
        )
        claims_merged = claims_merged.with_columns(
            (pl.col('Total cost(DEBIT_BY_CLIENT)') * 0.10).round(2).alias('commission')
        ).select([
            'groupname',
            'Total cost(DEBIT_BY_CLIENT)',
            'Total cost(claims)',
            'commission'
        ])
        claims_merged = claims_merged.with_columns([
            (
                (
                    pl.col('Total cost(claims)').fill_null(0) +
                    pl.col('commission').fill_null(0)
                ) / pl.col('Total cost(DEBIT_BY_CLIENT)').fill_null(0) * 100
            ).round(2).alias('MLR(CLAIMS) (%)')
        ])

        # Return both DataFrames
        return pa_merged, claims_merged
        
    except Exception as e:
        st.error(f"Error calculating MLR: {str(e)}")
        return pl.DataFrame(), pl.DataFrame()

# Main Streamlit app
if __name__ == "__main__":
    # Load data
    PA, GROUP_CONTRACT, CLAIMS, GROUPS, DEBIT = load_data_from_motherduck()
    
    if all(df is not None for df in [PA, GROUP_CONTRACT, CLAIMS, GROUPS, DEBIT]):
        # Calculate MLR
        pa_merged, claims_merged = calculate_mlr(PA, GROUP_CONTRACT, CLAIMS, GROUPS, DEBIT)
        
        if pa_merged.height > 0 or claims_merged.height > 0:
            st.subheader("MLR Analysis Results (PA)")
            if pa_merged.height > 0:
                # Convert to pandas for styling
                pa_df = pa_merged.to_pandas()
                
                # Create a function to highlight rows with MLR > 75%
                def highlight_high_mlr(row):
                    if row['MLR(PA) (%)'] > 75:
                        return ['background-color: #ffcccc; color: red; font-weight: bold'] * len(row)
                    return [''] * len(row)
                
                # Apply styling
                styled_pa_df = pa_df.style.apply(highlight_high_mlr, axis=1)
                st.dataframe(styled_pa_df, use_container_width=True)
                
                # Get companies with MLR > 75%
                high_mlr_pa_companies = pa_df[pa_df['MLR(PA) (%)'] > 75]['groupname'].tolist()
            else:
                st.warning("No PA MLR data available to display.")
                high_mlr_pa_companies = []

            st.subheader("MLR Analysis Results (Claims)")
            if claims_merged.height > 0:
                # Convert to pandas for styling
                claims_df = claims_merged.to_pandas()
                
                # Create a function to highlight rows with MLR > 75%
                def highlight_high_mlr_claims(row):
                    if row['MLR(CLAIMS) (%)'] > 75:
                        return ['background-color: #ffcccc; color: red; font-weight: bold'] * len(row)
                    return [''] * len(row)
                
                # Apply styling
                styled_claims_df = claims_df.style.apply(highlight_high_mlr_claims, axis=1)
                st.dataframe(styled_claims_df, use_container_width=True)
                
                # Get companies with MLR > 75%
                high_mlr_claims_companies = claims_df[claims_df['MLR(CLAIMS) (%)'] > 75]['groupname'].tolist()
            else:
                st.warning("No Claims MLR data available to display.")
                high_mlr_claims_companies = []
            
            # Display companies with high MLR
            st.subheader("ðŸš¨ Companies with MLR > 75%")
            
            if high_mlr_pa_companies or high_mlr_claims_companies:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**PA MLR > 75%:**")
                    if high_mlr_pa_companies:
                        for company in high_mlr_pa_companies:
                            st.markdown(f"â€¢ {company}")
                
                with col2:
                    st.markdown("**Claims MLR > 75%:**")
                    if high_mlr_claims_companies:
                        for company in high_mlr_claims_companies:
                            st.markdown(f"â€¢ {company}")
            else:
                st.success("âœ… No companies have MLR > 75%")
        else:
            st.warning("No MLR data available to display.")
    else:
        st.error("Failed to load data. Please check your connection and try again.")



